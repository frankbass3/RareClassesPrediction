{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STANFORD-Rarecalsses-IMAGE.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bOR6Ytd70n0kUE6qYk6et-Mgof1c3i5I",
      "authorship_tag": "ABX9TyOIZEqiriiRaGBu7zeK1iDz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankbass3/RareClassesPrediction/blob/main/STANFORD_Rarecalsses_IMAGE_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QX87b9N4LWp"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7MZS1iQ5Eve"
      },
      "source": [
        "%ls /content/drive/MyDrive/Colab\\ Notebooks/DATI-stanford-test-immagini/archive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFzQWjv47QXr"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/DATI-stanford-test-immagini/archive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXI4QuPCmKHK"
      },
      "source": [
        "data_root = tf.keras.utils.get_file(\r\n",
        "  'flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\r\n",
        "   untar=True)\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "img_height = 224\r\n",
        "img_width = 224\r\n",
        "\r\n",
        "tds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  str(data_root),\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"training\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size)\r\n",
        "\r\n",
        "vds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  str(data_root),\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"validation\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43VT7bX7qKQn"
      },
      "source": [
        "# for x,y in train_list_ds:\r\n",
        "#   print(y)\r\n",
        "#   break\r\n",
        "from IPython.display import Image, display\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "for x,y in tds:\r\n",
        "  print(x.shape)\r\n",
        "  for xx in x:\r\n",
        "    print(xx.shape)\r\n",
        "    plt.imshow(xx.numpy().astype('uint8'))\r\n",
        "    plt.show()\r\n",
        "    break\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcJCq0pbn3I-"
      },
      "source": [
        "total_x = []\r\n",
        "total = []\r\n",
        "for x,ba_y in tds:\r\n",
        "  list_y = []\r\n",
        "  for y in ba_y:\r\n",
        "    if y in [1,2,3,4]:\r\n",
        "      list_y.append(0)\r\n",
        "    else:\r\n",
        "      list_y.append(1)\r\n",
        "  \r\n",
        "  if ba_y.shape != 32:\r\n",
        "    continue\r\n",
        "  total.append(list_y)\r\n",
        "  total_x.append(x)\r\n",
        "  # print(x.shape)\r\n",
        "  # print(ba_y.shape)\r\n",
        "\r\n",
        "train_list_ds = tf.data.Dataset.from_tensor_slices((total_x, total))\r\n",
        "\r\n",
        "total_x = []\r\n",
        "total = []\r\n",
        "for x,ba_y in vds:\r\n",
        "  list_y = []\r\n",
        "  for y in ba_y:\r\n",
        "    if y in [1,2,3,4]:\r\n",
        "      list_y.append(0)\r\n",
        "    else:\r\n",
        "      list_y.append(1)\r\n",
        "  \r\n",
        "  if ba_y.shape != 32:\r\n",
        "    continue\r\n",
        "\r\n",
        "  total.append(list_y)\r\n",
        "  total_x.append(x)\r\n",
        "\r\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(( total_x, total))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO54F35KtWrB"
      },
      "source": [
        "print(len(list(train_list_ds.as_numpy_iterator())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHvfFRL_F8w4"
      },
      "source": [
        "#dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN, data_dir='data/')\r\n",
        "\r\n",
        "# Initialize VGG with the number of classes \r\n",
        "import tensorflow_hub as hub\r\n",
        "\r\n",
        "\r\n",
        "module_selection = (\"mobilenet_v2_100_224\", 224)\r\n",
        "handle_base, pixels = module_selection\r\n",
        "do_fine_tuning = False\r\n",
        "IMAGE_SIZE = (pixels, pixels)\r\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/{}/classification/4\".format(handle_base)\r\n",
        "\r\n",
        "\r\n",
        "pretrainmodel = tf.keras.Sequential([\r\n",
        "    # Explicitly define the input shape so the model can be properly\r\n",
        "    # loaded by the TFLiteConverter\r\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\r\n",
        "    hub.KerasLayer(MODULE_HANDLE, output_shape=[1001], trainable=do_fine_tuning),\r\n",
        "    # tf.keras.layers.Dropout(rate=0.2),\r\n",
        "    # tf.keras.layers.Dense(1280,\r\n",
        "    #                       kernel_regularizer=tf.keras.regularizers.l2(0.0001))\r\n",
        "])\r\n",
        "pretrainmodel.build((None,)+IMAGE_SIZE+(3,))\r\n",
        "pretrainmodel.summary()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckbX3j9vrue7"
      },
      "source": [
        "from tensorflow.python.keras.utils.vis_utils import plot_model\r\n",
        "plot_model(pretrainmodel, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G4Iim-LqVQy"
      },
      "source": [
        "numberofpsudoclass = 1001 \r\n",
        "\r\n",
        "def custom_loss(lam):\r\n",
        "  def loss(y_true, y_pred):\r\n",
        "    # Do your loss on your subset\r\n",
        "      y_pred_n_aux, y_pred_aux, pseudo_lables  = y_pred[:, :1], y_pred[:, 1:numberofpsudoclass+1], y_pred[:, numberofpsudoclass+1:]\r\n",
        "      cce1 = tf.keras.losses.CategoricalCrossentropy()\r\n",
        "      cce2 = tf.keras.losses.CategoricalCrossentropy()\r\n",
        "\r\n",
        "      l1 = cce1(y_true, y_pred_n_aux)\r\n",
        "      #tf.print(pseudo_lables)\r\n",
        "\r\n",
        "      l2 = cce2(pseudo_lables, y_pred_aux)\r\n",
        "      #l1 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_pred_n_aux, logits=y_true)\r\n",
        "      #l2 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_pred_aux,logits=pseudo_lables)\r\n",
        "      return (l1 + lam*l2) \r\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXBB2uB3Q_RS"
      },
      "source": [
        "import tensorflow_addons as tfa\r\n",
        "import sys\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\r\n",
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "from tensorflow.keras.datasets import fashion_mnist\r\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "def custom_layer(pseudo_lables):\r\n",
        "  #tf.print(input[0])\r\n",
        "  col_indices = tf.cast(tf.argmax(pseudo_lables, axis=1), tf.int32)\r\n",
        "  rows = tf.range(tf.shape(tf.argmax(pseudo_lables, axis=1))[0])\r\n",
        "  sta = tf.stack([rows,col_indices], axis=1)\r\n",
        "  # tf.print(tf.shape(pseudo_lables))\r\n",
        "  # tf.print(tf.shape(rows))\r\n",
        "  # tf.print(tf.shape(col_indices))\r\n",
        "  # tf.print(tf.shape(sta))\r\n",
        "  pred_max = tf.compat.v1.sparse_to_dense(sta,tf.shape(pseudo_lables),default_value=0.0,sparse_values=1.0)\r\n",
        "  return pred_max\r\n",
        "\r\n",
        "def custom_layer2(input):\r\n",
        "  tf.print(input)\r\n",
        "  return input\r\n",
        "\r\n",
        "METRICS = [\r\n",
        "      #tf.keras.metrics.TruePositives(name='tp'),\r\n",
        "      #tf.keras.metrics.FalsePositives(name='fp'),\r\n",
        "      #tf.keras.metrics.TrueNegatives(name='tn'),\r\n",
        "      #tf.keras.metrics.FalseNegatives(name='fn'), \r\n",
        "      tf.keras.metrics.Accuracy(name='accuracy'),\r\n",
        "      #tf.keras.metrics.Precision(name='precision'),\r\n",
        "      #tf.keras.metrics.Recall(name='recall'),\r\n",
        "      #tf.keras.metrics.AUC(name='auc'),\r\n",
        "      #tfa.metrics.F1Score(name='f1', num_classes=2)\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "num_classes = 1\r\n",
        "pseudo_lab_class = 1001\r\n",
        "\r\n",
        "input = Input(shape=(224, 224,3), name=\"base_input\")\r\n",
        "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3))(input)\r\n",
        "# x = Block(filters=64, kernel_size=3, repetitions=2)(x)\r\n",
        "# x = Block(filters=128, kernel_size=3, repetitions=2)(x)\r\n",
        "# x = Block(filters=256, kernel_size=3, repetitions=3)(x)\r\n",
        "# x = Block(filters=512, kernel_size=3, repetitions=3)(x)\r\n",
        "# x = Block(filters=512, kernel_size=3, repetitions=3)(x)\r\n",
        "x = tf.keras.layers.Conv2D(16, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Conv2D(32, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Conv2D(64, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Flatten()(x)\r\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\r\n",
        "\r\n",
        "\r\n",
        "y = tf.keras.layers.Dense(num_classes,activation='softmax')(x)\r\n",
        "y2 = tf.keras.layers.Dense(pseudo_lab_class, activation='softmax')(x)\r\n",
        "\r\n",
        "x2 = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3))(input)\r\n",
        "y_pseudo_lab = pretrainmodel(x2)\r\n",
        "#y_pseudo_lab = tf.keras.layers.Lambda(custom_layer2)(y_pseudo_lab)\r\n",
        "y_pseudo_lab = tf.keras.layers.Lambda(custom_layer)(y_pseudo_lab)\r\n",
        "\r\n",
        "concat = tf.keras.layers.Concatenate()([y,y2,y_pseudo_lab])\r\n",
        "\r\n",
        "archi = Model(inputs=input, outputs=concat)\r\n",
        "archi.compile(loss=custom_loss(0.2), optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),metrics='accuracy')\r\n",
        "#tb_callback = tf.keras.callbacks.TensorBoard('/content/', update_freq=1)\r\n",
        "\r\n",
        "# tf.debugging.experimental.enable_dump_debug_info(\r\n",
        "#    # logdir=\"/content/tfdbg2_logdir\",\r\n",
        "#     tensor_debug_mode=\"FULL_HEALTH\",\r\n",
        "#     circular_buffer_size=-1,\r\n",
        "#     dump_root='/content/')\r\n",
        "\r\n",
        "history = archi.fit(\r\n",
        "  train_list_ds,\r\n",
        "  validation_data=val_ds,\r\n",
        "  epochs=9  #\r\n",
        "   #callbacks=[tb_callback]\r\n",
        ")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypw5q1p4iTKs"
      },
      "source": [
        "import tensorflow_addons as tfa\r\n",
        "import sys\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\r\n",
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "from tensorflow.keras.datasets import fashion_mnist\r\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "\r\n",
        "METRICS = [\r\n",
        "      #tf.keras.metrics.TruePositives(name='tp'),\r\n",
        "      #tf.keras.metrics.FalsePositives(name='fp'),\r\n",
        "      #tf.keras.metrics.TrueNegatives(name='tn'),\r\n",
        "      #tf.keras.metrics.FalseNegatives(name='fn'), \r\n",
        "      tf.keras.metrics.Accuracy(name='accuracy'),\r\n",
        "      #tf.keras.metrics.Precision(name='precision'),\r\n",
        "      #tf.keras.metrics.Recall(name='recall'),\r\n",
        "      #tf.keras.metrics.AUC(name='auc'),\r\n",
        "      #tfa.metrics.F1Score(name='f1', num_classes=2)\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "pseudo_lab_class = 1001\r\n",
        "\r\n",
        "input = Input(shape=(224, 224,3), name=\"base_input\")\r\n",
        "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3))(input)\r\n",
        "x = tf.keras.layers.Conv2D(16, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Conv2D(32, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Conv2D(64, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Flatten()(x)\r\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\r\n",
        "\r\n",
        "y = tf.keras.layers.Dense(1,activation='softmax')(x)\r\n",
        "\r\n",
        "archi = Model(inputs=input, outputs=y)\r\n",
        "archi.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),metrics=METRICS)\r\n",
        "\r\n",
        "history = archi.fit(\r\n",
        "  train_list_ds,\r\n",
        "  validation_data=val_ds,\r\n",
        "  epochs=15  #\r\n",
        "   #callbacks=[tb_callback]\r\n",
        ")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHe--ScL_Lg0"
      },
      "source": [
        "plot_model(archi, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-QwcFU6l3T_"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "\r\n",
        "%tensorboard --logdir /content/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-FGsWnVDmQX"
      },
      "source": [
        "tensorboard --logdir /content/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}