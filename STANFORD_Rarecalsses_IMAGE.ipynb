{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STANFORD-Rarecalsses-IMAGE.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bOR6Ytd70n0kUE6qYk6et-Mgof1c3i5I",
      "authorship_tag": "ABX9TyON+PrcV+tE+3utdUnvozpT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frankbass3/RareClassesPrediction/blob/main/STANFORD_Rarecalsses_IMAGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QX87b9N4LWp"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7MZS1iQ5Eve"
      },
      "source": [
        "%ls /content/drive/MyDrive/Colab\\ Notebooks/DATI-stanford-test-immagini/archive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFzQWjv47QXr"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/DATI-stanford-test-immagini/archive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3IJMZc67h6y"
      },
      "source": [
        "# df = pd.read_csv(\"data_example.csv\")\r\n",
        "from PIL import Image\r\n",
        "im = Image.open(\"./buffalo/002.jpg\")\r\n",
        "im.show()\r\n",
        "im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t17SGA1vtB4"
      },
      "source": [
        "%rm ./buffalo/*.txt\r\n",
        "%rm ./elephant/*.txt\r\n",
        "%rm ./rhino/*.txt\r\n",
        "%rm ./zebra/*.txt\r\n",
        "%rm ./outer-model.png\r\n",
        "%rm ./model.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyI4v5ELuZy3"
      },
      "source": [
        "%ls ./\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB0gu4utvCBc"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "batch_size = 32\r\n",
        "img_height = 224\r\n",
        "img_width = 224\r\n",
        "\r\n",
        "train_list_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  './',\r\n",
        "  validation_split=0.3,\r\n",
        "  subset=\"training\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size)\r\n",
        "\r\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  './',\r\n",
        "  validation_split=0.3,\r\n",
        "  subset=\"validation\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1evbClN5F69T"
      },
      "source": [
        "\r\n",
        "class Block(tf.keras.Model):\r\n",
        "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\r\n",
        "        super(Block, self).__init__()\r\n",
        "        self.filters = filters\r\n",
        "        self.kernel_size = kernel_size\r\n",
        "        self.repetitions = repetitions\r\n",
        "      \r\n",
        "        # Define a conv2D_0, conv2D_1, etc based on the number of repetitions\r\n",
        "        for i in range(repetitions):\r\n",
        "          \r\n",
        "            # Define a Conv2D layer, specifying filters, kernel_size, activation and padding.\r\n",
        "            vars(self)[f'conv2D_{i}'] = tf.keras.layers.Conv2D(self.filters,\r\n",
        "                                                               self.kernel_size,\r\n",
        "                                                               activation = 'relu',\r\n",
        "                                                               padding = 'same')\r\n",
        "      \r\n",
        "        # Define the max pool layer that will be added after the Conv2D blocks\r\n",
        "        # Note on pool_size and strides:\r\n",
        "        # If only one integer is specified, the same window length will be used for both dimensions.\r\n",
        "        self.max_pool = tf.keras.layers.MaxPool2D(pool_size=pool_size,\r\n",
        "                                                  strides=strides,\r\n",
        "                                                 padding='same')\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        # access the class's conv2D_0 layer\r\n",
        "        print(inputs)\r\n",
        "        conv2D_0 = vars(self)['conv2D_0']\r\n",
        "      \r\n",
        "        # Connect the conv2D_0 layer to inputs\r\n",
        "        x = conv2D_0(inputs)\r\n",
        "\r\n",
        "        # for the remaining conv2D_i layers from 1 to `repetitions` they will be connected to the previous layer\r\n",
        "        for i in range(1,self.repetitions):\r\n",
        "            # access conv2D_i by formatting the integer `i`. (hint: check how these were saved using `vars()` earlier)\r\n",
        "            conv2D_i = vars(self)[f'conv2D_{i}']\r\n",
        "          \r\n",
        "            # Use the conv2D_i and connect it to the previous layer\r\n",
        "            x = conv2D_i(x)\r\n",
        "\r\n",
        "        # Finally, add the max_pool layer\r\n",
        "        max_pool = self.max_pool(x)\r\n",
        "      \r\n",
        "        return max_pool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjU7o7zhFn14"
      },
      "source": [
        "from tensorflow.keras.models import Model\r\n",
        "\r\n",
        "class NotAuxiliaryModel(tf.keras.Model):\r\n",
        "\r\n",
        "  def __init__(self, num_classes, pseudo_lables, pretrained_model): # andrebbe aggiunto num_classes per le pseudo\r\n",
        "    super(NotAuxiliaryModel, self).__init__()\r\n",
        "\r\n",
        "      # Creating blocks of VGG with the following \r\n",
        "      # (filters, kernel_size, repetitions) configurations\r\n",
        "    self.block_a = Block(filters=64, kernel_size=3, repetitions=2)\r\n",
        "    self.block_b = Block(filters=128, kernel_size=3, repetitions=2)\r\n",
        "    self.block_c = Block(filters=256, kernel_size=3, repetitions=3)\r\n",
        "    self.block_d = Block(filters=512, kernel_size=3, repetitions=3)\r\n",
        "    self.block_e = Block(filters=512, kernel_size=3, repetitions=3)\r\n",
        "        \r\n",
        "      # Classification head\r\n",
        "      # Define a Flatten layer\r\n",
        "    self.flatten = tf.keras.layers.Flatten()\r\n",
        "\r\n",
        "      # Create a Dense layer with 256 units and ReLU as the activation function\r\n",
        "    self.fc = tf.keras.layers.Dense(256, activation='relu')\r\n",
        "    # Finally add the softmax classifier using a Dense layer\r\n",
        "    self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax') \r\n",
        "    # \r\n",
        "\r\n",
        "    self.pseudo_lables = pseudo_lables\r\n",
        "    self.classifier_aux = tf.keras.layers.Dense(pseudo_lables, activation='softmax') # \r\n",
        "    self.classifier_pseudo = pretrained_model\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    x = self.block_a(inputs) \r\n",
        "    x = self.block_b(x)\r\n",
        "    x = self.block_c(x)\r\n",
        "    x = self.block_d(x)\r\n",
        "    x = self.block_e(x)\r\n",
        "    x = self.flatten(x)\r\n",
        "    x = self.fc(x)\r\n",
        "\r\n",
        "\r\n",
        "    output_main = self.classifier(x)#,name='output_1')\r\n",
        "    output_aux = self.classifier_aux(x)#,name='output_2')\r\n",
        "    pseudo_labels = self.classifier_pseudo(inputs)\r\n",
        "\r\n",
        "\r\n",
        "    return Model(inputs = inputs, outputs=[output_main,output_aux,pseudo_labels])  #x , x_aux"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXI4QuPCmKHK"
      },
      "source": [
        "data_root = tf.keras.utils.get_file(\r\n",
        "  'flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\r\n",
        "   untar=True)\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "img_height = 224\r\n",
        "img_width = 224\r\n",
        "\r\n",
        "tds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  str(data_root),\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"training\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size)\r\n",
        "\r\n",
        "vds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  str(data_root),\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"validation\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(img_height, img_width),\r\n",
        "  batch_size=batch_size)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43VT7bX7qKQn"
      },
      "source": [
        "# for x,y in train_list_ds:\r\n",
        "#   print(y)\r\n",
        "#   break\r\n",
        "from IPython.display import Image, display\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "for x,y in tds:\r\n",
        "  print(x.shape)\r\n",
        "  for xx in x:\r\n",
        "    print(xx.shape)\r\n",
        "    plt.imshow(xx.numpy().astype('uint8'))\r\n",
        "    plt.show()\r\n",
        "    break\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcJCq0pbn3I-"
      },
      "source": [
        "total_x = []\r\n",
        "total = []\r\n",
        "for x,ba_y in tds:\r\n",
        "  list_y = []\r\n",
        "  for y in ba_y:\r\n",
        "    if y in [1,2,3,4]:\r\n",
        "      list_y.append(0)\r\n",
        "    else:\r\n",
        "      list_y.append(1)\r\n",
        "  \r\n",
        "  if ba_y.shape != 32:\r\n",
        "    continue\r\n",
        "  total.append(list_y)\r\n",
        "  total_x.append(x)\r\n",
        "  # print(x.shape)\r\n",
        "  # print(ba_y.shape)\r\n",
        "\r\n",
        "train_list_ds = tf.data.Dataset.from_tensor_slices((total_x, total))\r\n",
        "\r\n",
        "total_x = []\r\n",
        "total = []\r\n",
        "for x,ba_y in vds:\r\n",
        "  list_y = []\r\n",
        "  for y in ba_y:\r\n",
        "    if y in [1,2,3,4]:\r\n",
        "      list_y.append(0)\r\n",
        "    else:\r\n",
        "      list_y.append(1)\r\n",
        "  \r\n",
        "  if ba_y.shape != 32:\r\n",
        "    continue\r\n",
        "\r\n",
        "  total.append(list_y)\r\n",
        "  total_x.append(x)\r\n",
        "\r\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(( total_x, total))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO54F35KtWrB"
      },
      "source": [
        "print(len(list(train_list_ds.as_numpy_iterator())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHvfFRL_F8w4"
      },
      "source": [
        "#dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN, data_dir='data/')\r\n",
        "\r\n",
        "# Initialize VGG with the number of classes \r\n",
        "import tensorflow_hub as hub\r\n",
        "\r\n",
        "\r\n",
        "module_selection = (\"mobilenet_v2_100_224\", 224)\r\n",
        "handle_base, pixels = module_selection\r\n",
        "do_fine_tuning = False\r\n",
        "IMAGE_SIZE = (pixels, pixels)\r\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/{}/classification/4\".format(handle_base)\r\n",
        "\r\n",
        "\r\n",
        "pretrainmodel = tf.keras.Sequential([\r\n",
        "    # Explicitly define the input shape so the model can be properly\r\n",
        "    # loaded by the TFLiteConverter\r\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\r\n",
        "    hub.KerasLayer(MODULE_HANDLE, output_shape=[1001], trainable=do_fine_tuning),\r\n",
        "    # tf.keras.layers.Dropout(rate=0.2),\r\n",
        "    # tf.keras.layers.Dense(1280,\r\n",
        "    #                       kernel_regularizer=tf.keras.regularizers.l2(0.0001))\r\n",
        "])\r\n",
        "pretrainmodel.build((None,)+IMAGE_SIZE+(3,))\r\n",
        "pretrainmodel.summary()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckbX3j9vrue7"
      },
      "source": [
        "from tensorflow.python.keras.utils.vis_utils import plot_model\r\n",
        "plot_model(pretrainmodel, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G4Iim-LqVQy"
      },
      "source": [
        "numberofpsudoclass = 1001 \r\n",
        "\r\n",
        "def custom_loss(lam):\r\n",
        "  def loss(y_true, y_pred):\r\n",
        "    # Do your loss on your subset\r\n",
        "      y_pred_n_aux, y_pred_aux, pseudo_lables  = y_pred[:, :1], y_pred[:, 1:numberofpsudoclass+1], y_pred[:, numberofpsudoclass+1:]\r\n",
        "      cce1 = tf.keras.losses.CategoricalCrossentropy()\r\n",
        "      cce2 = tf.keras.losses.CategoricalCrossentropy()\r\n",
        "\r\n",
        "      l1 = cce1(y_true, y_pred_n_aux)\r\n",
        "      #tf.print(pseudo_lables)\r\n",
        "\r\n",
        "      l2 = cce2(pseudo_lables, y_pred_aux)\r\n",
        "      #l1 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_pred_n_aux, logits=y_true)\r\n",
        "      #l2 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_pred_aux,logits=pseudo_lables)\r\n",
        "      return (l1 + lam*l2) \r\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXBB2uB3Q_RS"
      },
      "source": [
        "import tensorflow_addons as tfa\r\n",
        "import sys\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\r\n",
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "from tensorflow.keras.datasets import fashion_mnist\r\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "def custom_layer(pseudo_lables):\r\n",
        "  #tf.print(input[0])\r\n",
        "  col_indices = tf.cast(tf.argmax(pseudo_lables, axis=1), tf.int32)\r\n",
        "  rows = tf.range(tf.shape(tf.argmax(pseudo_lables, axis=1))[0])\r\n",
        "  sta = tf.stack([rows,col_indices], axis=1)\r\n",
        "  # tf.print(tf.shape(pseudo_lables))\r\n",
        "  # tf.print(tf.shape(rows))\r\n",
        "  # tf.print(tf.shape(col_indices))\r\n",
        "  # tf.print(tf.shape(sta))\r\n",
        "  pred_max = tf.compat.v1.sparse_to_dense(sta,tf.shape(pseudo_lables),default_value=0.0,sparse_values=1.0)\r\n",
        "  return pred_max\r\n",
        "\r\n",
        "def custom_layer2(input):\r\n",
        "  tf.print(input)\r\n",
        "  return input\r\n",
        "\r\n",
        "METRICS = [\r\n",
        "      #tf.keras.metrics.TruePositives(name='tp'),\r\n",
        "      #tf.keras.metrics.FalsePositives(name='fp'),\r\n",
        "      #tf.keras.metrics.TrueNegatives(name='tn'),\r\n",
        "      #tf.keras.metrics.FalseNegatives(name='fn'), \r\n",
        "      tf.keras.metrics.Accuracy(name='accuracy'),\r\n",
        "      #tf.keras.metrics.Precision(name='precision'),\r\n",
        "      #tf.keras.metrics.Recall(name='recall'),\r\n",
        "      #tf.keras.metrics.AUC(name='auc'),\r\n",
        "      #tfa.metrics.F1Score(name='f1', num_classes=2)\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "num_classes = 1\r\n",
        "pseudo_lab_class = 1001\r\n",
        "\r\n",
        "input = Input(shape=(224, 224,3), name=\"base_input\")\r\n",
        "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3))(input)\r\n",
        "# x = Block(filters=64, kernel_size=3, repetitions=2)(x)\r\n",
        "# x = Block(filters=128, kernel_size=3, repetitions=2)(x)\r\n",
        "# x = Block(filters=256, kernel_size=3, repetitions=3)(x)\r\n",
        "# x = Block(filters=512, kernel_size=3, repetitions=3)(x)\r\n",
        "# x = Block(filters=512, kernel_size=3, repetitions=3)(x)\r\n",
        "x = tf.keras.layers.Conv2D(16, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Conv2D(32, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Conv2D(64, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Flatten()(x)\r\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\r\n",
        "\r\n",
        "\r\n",
        "y = tf.keras.layers.Dense(num_classes,activation='softmax')(x)\r\n",
        "y2 = tf.keras.layers.Dense(pseudo_lab_class, activation='softmax')(x)\r\n",
        "\r\n",
        "x2 = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3))(input)\r\n",
        "y_pseudo_lab = pretrainmodel(x2)\r\n",
        "#y_pseudo_lab = tf.keras.layers.Lambda(custom_layer2)(y_pseudo_lab)\r\n",
        "y_pseudo_lab = tf.keras.layers.Lambda(custom_layer)(y_pseudo_lab)\r\n",
        "\r\n",
        "concat = tf.keras.layers.Concatenate()([y,y2,y_pseudo_lab])\r\n",
        "\r\n",
        "archi = Model(inputs=input, outputs=concat)\r\n",
        "archi.compile(loss=custom_loss(0.2), optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),metrics='accuracy')\r\n",
        "#tb_callback = tf.keras.callbacks.TensorBoard('/content/', update_freq=1)\r\n",
        "\r\n",
        "# tf.debugging.experimental.enable_dump_debug_info(\r\n",
        "#    # logdir=\"/content/tfdbg2_logdir\",\r\n",
        "#     tensor_debug_mode=\"FULL_HEALTH\",\r\n",
        "#     circular_buffer_size=-1,\r\n",
        "#     dump_root='/content/')\r\n",
        "\r\n",
        "history = archi.fit(\r\n",
        "  train_list_ds,\r\n",
        "  validation_data=val_ds,\r\n",
        "  epochs=9  #\r\n",
        "   #callbacks=[tb_callback]\r\n",
        ")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypw5q1p4iTKs"
      },
      "source": [
        "import tensorflow_addons as tfa\r\n",
        "import sys\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\r\n",
        "from tensorflow.keras.optimizers import RMSprop\r\n",
        "from tensorflow.keras.datasets import fashion_mnist\r\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "\r\n",
        "METRICS = [\r\n",
        "      #tf.keras.metrics.TruePositives(name='tp'),\r\n",
        "      #tf.keras.metrics.FalsePositives(name='fp'),\r\n",
        "      #tf.keras.metrics.TrueNegatives(name='tn'),\r\n",
        "      #tf.keras.metrics.FalseNegatives(name='fn'), \r\n",
        "      tf.keras.metrics.Accuracy(name='accuracy'),\r\n",
        "      #tf.keras.metrics.Precision(name='precision'),\r\n",
        "      #tf.keras.metrics.Recall(name='recall'),\r\n",
        "      #tf.keras.metrics.AUC(name='auc'),\r\n",
        "      #tfa.metrics.F1Score(name='f1', num_classes=2)\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "pseudo_lab_class = 1001\r\n",
        "\r\n",
        "input = Input(shape=(224, 224,3), name=\"base_input\")\r\n",
        "x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3))(input)\r\n",
        "x = tf.keras.layers.Conv2D(16, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Conv2D(32, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Conv2D(64, 3, padding='same', activation=tf.nn.relu)(x)\r\n",
        "x = tf.keras.layers.MaxPooling2D()(x)\r\n",
        "x = tf.keras.layers.Flatten()(x)\r\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\r\n",
        "\r\n",
        "y = tf.keras.layers.Dense(1,activation='softmax')(x)\r\n",
        "\r\n",
        "archi = Model(inputs=input, outputs=y)\r\n",
        "archi.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),metrics=METRICS)\r\n",
        "\r\n",
        "history = archi.fit(\r\n",
        "  train_list_ds,\r\n",
        "  validation_data=val_ds,\r\n",
        "  epochs=15  #\r\n",
        "   #callbacks=[tb_callback]\r\n",
        ")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHe--ScL_Lg0"
      },
      "source": [
        "plot_model(archi, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-QwcFU6l3T_"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "\r\n",
        "%tensorboard --logdir /content/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-FGsWnVDmQX"
      },
      "source": [
        "tensorboard --logdir /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72OxUwtGeyZH"
      },
      "source": [
        "\r\n",
        "def custompreprocess(features,param):\r\n",
        "    # Resize and normalize\r\n",
        "    print(param)\r\n",
        "    image = tf.image.resize(in_image, (224, 224))\r\n",
        "    return tf.cast(image, tf.float32) / 255., param\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHwrlmsQLZXr"
      },
      "source": [
        "vgg = NotAuxiliaryModel(num_classes=2, pseudo_lables=1280, pretrained_model=pretrainmodel)\r\n",
        "\r\n",
        "\r\n",
        "# output_layer_1 = [layer for layer in vgg.layers if layer.name == 'output_1'][0]\r\n",
        "# losses = {'output_1': 'categorical_crossentropy', 'output_2': custom_loss(vgg, output_layer_1.output)}\r\n",
        "\r\n",
        "vgg.compile(loss=custom_loss(0.5), optimizer='adam',metrics=['accuracy'])\r\n",
        "#vgg.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\r\n",
        "\r\n",
        "# Compile with losses and metrics\r\n",
        "#vgg.compile(optimizer='adam', loss=wrap_custom_loss, metrics=['accuracy'])\r\n",
        "\r\n",
        "# Define preprocessing function\r\n",
        "\r\n",
        "# Apply transformations to dataset\r\n",
        "#train_list_ds = train_list_ds.map(custompreprocess).batch(32)\r\n",
        "\r\n",
        "# Train the custom VGG model\r\n",
        "# y_lables = np.concatenate([y for x, y in train_list_ds], axis=0)\r\n",
        "# x_train = np.concatenate([x for x, y in train_list_ds], axis=0)\r\n",
        "\r\n",
        "vgg.fit(\r\n",
        "  train_list_ds,\r\n",
        "  validation_data=val_ds,\r\n",
        "  epochs=3\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4YqATD8hf40"
      },
      "source": [
        "#layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\r\n",
        "for image_batch, labels_batch in train_list_ds:\r\n",
        "  print(image_batch.shape)\r\n",
        "  print(labels_batch.shape)\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZIXeXsdyOgG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q48s-cP0qcEI"
      },
      "source": [
        "import tensorflow as tf \r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "\r\n",
        "# list_foreground = []\r\n",
        "# list_test = []\r\n",
        "# list_val = []\r\n",
        "# list_background = []\r\n",
        "\r\n",
        "# buff = glob.glob(f\"./buffalo/*.jpg\")\r\n",
        "# elephant = glob.glob(f\"./elephant/*.jpg\")\r\n",
        "# rhino = glob.glob(f\"./rhino/*.jpg\")\r\n",
        "# zebra = glob.glob(f\"./zebra/*.jpg\")\r\n",
        "\r\n",
        "# max_train = 200\r\n",
        "# max_test = 100\r\n",
        "# max_validation = 75\r\n",
        "\r\n",
        "# for file in buff:  \r\n",
        "#   list_foreground.append(file)\r\n",
        "\r\n",
        "# for file in elephant:\r\n",
        "#   list_background.append(file)\r\n",
        "\r\n",
        "# for file in rhino:\r\n",
        "#   list_background.append(file)\r\n",
        "\r\n",
        "# for file in zebra:\r\n",
        "#   list_background.append(file)\r\n",
        "\r\n",
        "\r\n",
        "# labels = np.ones(len(list_foreground))\r\n",
        "# print('lables shape',labels.shape)\r\n",
        "# labels_background = np.zeros(len(list_background))\r\n",
        "# print('background shape',labels_background.shape)\r\n",
        "# labs = np.concatenate((labels, labels_background), axis=None)\r\n",
        "# print('shape:' , labs.shape)\r\n",
        "\r\n",
        "# processed = []\r\n",
        "# for x in list_foreground:\r\n",
        "#   processed.append(tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(x)))\r\n",
        "\r\n",
        "# for x in list_background:\r\n",
        "#   processed.append(tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(x)))\r\n",
        "\r\n",
        "# filenames = tf.constant(processed)\r\n",
        "# dataset = tf.data.Dataset.from_tensor_slices((filenames, labs))\r\n",
        "\r\n",
        "# ds = dataset.cache()\r\n",
        "\r\n",
        "# # Add some indices.\r\n",
        "# ds = ds.enumerate()\r\n",
        "\r\n",
        "# # Do a rougly 70-30 split.\r\n",
        "# train_list_ds = ds.filter(lambda i, data: i % 10 <= 7)\r\n",
        "\r\n",
        "# test_valid_ds = ds.filter(lambda i, data: i % 10 > 7 and i%10 <=9)\r\n",
        "\r\n",
        "# test_list_ds = ds.filter(lambda i, data: i % 10 > 9)\r\n",
        "\r\n",
        "\r\n",
        "# # Drop indices.\r\n",
        "# train_list_ds = train_list_ds.map(lambda i, data: data)\r\n",
        "\r\n",
        "# test_valid_ds = test_valid_ds.map(lambda i, data: data)\r\n",
        "\r\n",
        "# test_list_ds = test_list_ds.map(lambda i, data: data)\r\n",
        "\r\n",
        "# print(len(list(test_list_ds.as_numpy_iterator())))\r\n",
        "# print(len(list(train_list_ds.as_numpy_iterator())))\r\n",
        "# print(len(list(test_valid_ds.as_numpy_iterator())))\r\n",
        "\r\n",
        "#list(test_list_ds.as_numpy_iterator())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}